name: Deploy to EKS

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout Code
      - name: Checkout Code
        uses: actions/checkout@v3

      # Step 2: Set up AWS CLI Credentials
      - name: Set up AWS CLI Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      # Step 3: Verify EKS Cluster
      - name: Verify EKS Cluster
        id: verify-cluster
        run: |
          CLUSTER_STATUS=$(aws eks describe-cluster --name ${{ secrets.EKS_CLUSTER_NAME }} --region ${{ secrets.AWS_REGION }} --query "cluster.status" --output text || echo "NOT_FOUND")
          echo "CLUSTER_EXISTS=$CLUSTER_STATUS" >> $GITHUB_ENV
          echo "Cluster Status: $CLUSTER_STATUS"
      
      # Step 4: Clean Terraform directory
      - name: Clean Terraform directory
        run: |
          rm -rf .terraform .terraform.lock.hcl terraform.tfstate terraform.tfstate.backup

      # Step 5: Set up Terraform
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.8.4

      # Step 6: Terraform Init
      - name: Terraform Init
        run: terraform init -upgrade
        working-directory: ./terraform/eks-cluster

      # Step 7: Terraform Plan
      - name: Terraform Plan
        run: terraform plan -out=tfplan
        working-directory: ./terraform/eks-cluster

      # Step 8: Terraform Apply
      - name: Terraform Apply
        run: |
          if [[ "$CLUSTER_EXISTS" == "NOT_FOUND" ]]; then
            echo "Cluster does not exist. Creating a new EKS cluster..."
            terraform apply -auto-approve tfplan
          else
            echo "Cluster exists. Updating the EKS cluster..."
            terraform apply -refresh-only -auto-approve
          fi
        working-directory: ./terraform/eks-cluster

      # Step 9: Extract Terraform Outputs
      - name: Extract Terraform Outputs
        id: outputs
        run: |
          echo "EKS_CLUSTER_NAME=\"$(terraform output -raw cluster_name)\"" >> $GITHUB_ENV || exit 1
          echo "REGION=\"$(terraform output -raw region)\"" >> $GITHUB_ENV || exit 1
          echo "EKS_CLUSTER_ENDPOINT=\"$(terraform output -raw cluster_endpoint)\"" >> $GITHUB_ENV || exit 1
          echo "EKS_CLUSTER_CA_DATA=\"$(terraform output -raw cluster_certificate_authority_data)\"" >> $GITHUB_ENV || exit 1
        working-directory: ./terraform/eks-cluster
        env:
          TERRAFORM_CLI_PATH: ./terraform/eks-cluster

      - name: Download kubeconfig to local
        run: |
          mkdir -p ~/.kube
          aws eks --region ${{ secrets.AWS_REGION }} update-kubeconfig --name ${{ secrets.EKS_CLUSTER_NAME }} --kubeconfig ~/.kube/config
          echo "Kubeconfig saved to ~/.kube/config"
          export KUBECONFIG=~/.kube/config
          kubectl get nodes

      - name: Create HPA for the App
        run: |
          kubectl create namespace fargate-applications
          kubectl apply -f ./k8s/hpa.yaml
      
      - name: Check HPA Status
        run: |
          kubectl get hpa

      # Step 12: Deploy Backend API
      - name: Deploy Backend API
        run: |
          helm repo add eks https://aws.github.io/eks-charts
          helm repo update eks
          helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
            -n kube-system \
            --set clusterName=${{ secrets.EKS_CLUSTER_NAME }} \
            --set serviceAccount.create=false \
            --set serviceAccount.name=aws-load-balancer-controller
      
      # Cleanup on Failure
      - name: Terraform Destroy on Failure
        if: ${{ failure() || cancelled() }}
        run: terraform destroy -auto-approve
        working-directory: ./terraform/eks-cluster

      # Step 12: Deploy Backend API
      - name: Deploy Backend API
        run: |
          helm upgrade --install backend-api ./deployment/backend \
           --set image.repository=${{ env.ECR_REPO }}/backend-api \
           --set image.tag=latest --namespace fargate-applications --create-namespace
        env:
          KUBECONFIG: ${{ secrets.KUBECONFIG }}

      # Step 13: Deploy Frontend UI
      - name: Deploy Frontend UI
        run: |
          helm upgrade --install frontend-ui ./deployment/frontend \
            --set image.repository=${{ env.ECR_REPO }}/frontend-ui \
            --set image.tag=latest --namespace fargate-applications --create-namespace
        env:
          KUBECONFIG: ${{ secrets.KUBECONFIG }}